# Llama-3-SynE

<p align="center">
 ğŸ“„<a href="https://arxiv.org/abs/2407.18743" target="_blank"> æŠ¥å‘Š </a> â€¢ ğŸ¤— <a href="https://huggingface.co/survivi/Llama-3-SynE" target="_blank">Hugging Face ä»“åº“</a>
</p>

<p align="center">
 ğŸ”<a href="README.md" target="_blank">English</a>
</p>

## æ›´æ–°
- âœ¨âœ¨ ``2024/08/10``: æˆ‘ä»¬å‘å¸ƒäº† [Llama-3-SynE æ¨¡å‹](https://huggingface.co/survivi/Llama-3-SynE)ã€‚
- âœ¨ ``2024/07/26``: æˆ‘ä»¬å‘å¸ƒäº† Llama-3-SynE çš„ [æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2407.18743)ï¼Œæ¬¢è¿æŸ¥é˜…ï¼

## æ¨¡å‹ä»‹ç»

**Llama-3-SynE**ï¼ˆ**Syn**thetic data **E**nhanced Llama-3ï¼‰æ˜¯ [Llama-3ï¼ˆ8Bï¼‰](https://github.com/meta-llama/llama3)çš„å¢å¼ºç‰ˆï¼Œé€šè¿‡ç»§ç»­é¢„è®­ç»ƒï¼ˆcontinual pre-trainingï¼ŒCPTï¼‰æ¥æå‡å…¶**ä¸­æ–‡è¯­è¨€èƒ½åŠ›å’Œç§‘å­¦æ¨ç†èƒ½åŠ›**ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ•°æ®æ··åˆå’Œè¯¾ç¨‹ç­–ç•¥ï¼ŒLlama-3-SynE æˆåŠŸåœ°åœ¨ä¿æŒåŸå§‹æ¨¡å‹æ€§èƒ½çš„åŒæ—¶å¢å¼ºäº†æ–°èƒ½åŠ›ã€‚è¿™ä¸ªå¢å¼ºè¿‡ç¨‹åŒ…æ‹¬åˆ©ç”¨ç°æœ‰æ•°æ®é›†å¹¶åˆæˆä¸“é—¨ä¸ºç›®æ ‡ä»»åŠ¡è®¾è®¡çš„é«˜è´¨é‡æ•°æ®é›†ã€‚

Llama-3-SynE çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š
- **å¢å¼ºçš„ä¸­æ–‡è¯­è¨€èƒ½åŠ›**ï¼šé€šè¿‡åŸºäºä¸»é¢˜çš„æ•°æ®æ··åˆå’ŒåŸºäºå›°æƒ‘åº¦çš„æ•°æ®è¯¾ç¨‹å®ç°ã€‚
- **æ”¹è¿›çš„ç§‘å­¦æ¨ç†èƒ½åŠ›**ï¼šåˆ©ç”¨åˆæˆæ•°æ®é›†æ¥å¢å¼ºå¤šå­¦ç§‘çš„ç§‘å­¦çŸ¥è¯†ã€‚
- **é«˜æ•ˆçš„ç»§ç»­é¢„è®­ç»ƒ**ï¼šåªæ¶ˆè€—çº¦ 1000 äº¿ä¸ª tokenï¼Œæˆæœ¬æ•ˆç›Šé«˜ã€‚

## æ¨¡å‹åˆ—è¡¨

| æ¨¡å‹            | ç±»å‹  | åºåˆ—é•¿åº¦ | ä¸‹è½½                                                                                                                      |
|-----------------|-------|----------|---------------------------------------------------------------------------------------------------------------------------|
| Llama-3-SynE    | Base  | 8K       | [ğŸ¤— Huggingface](https://huggingface.co/survivi/Llama-3-SynE) |

## åŸºå‡†æµ‹è¯•

æˆ‘ä»¬å°†æ‰€æœ‰è¯„ä¼°åŸºå‡†åˆ†ä¸ºä¸¤ç»„ã€‚ç¬¬ä¸€ç»„æ˜¯ _ä¸»è¦åŸºå‡†_ï¼Œæ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„ç»¼åˆèƒ½åŠ›ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯æˆ‘ä»¬åœ¨è¿™ä¸€ç»„åŸºå‡†ä¸­åŒ…æ‹¬äº†å¸¸ç”¨çš„æ•°å­¦å’Œä»£ç åŸºå‡†ï¼Œå› ä¸ºä½¿ç”¨è¿™äº›åŸºå‡†è¯„ä¼°å„ç§é€šç”¨å¤§è¯­è¨€æ¨¡å‹æ˜¯æ ‡å‡†åšæ³•ã€‚

ç¬¬äºŒç»„æ˜¯ _ç§‘å­¦åŸºå‡†_ï¼Œæ¶µç›–äº†å¤šå­¦ç§‘çš„ç§‘å­¦çŸ¥è¯†ã€‚

æˆ‘ä»¬æŠ¥å‘Šäº†åœ¨ GSM8Kã€ASDiv å’Œ MAWPS ä¸Šçš„ 8-shot æ€§èƒ½ï¼ŒC-Evalã€CMMLUã€MMLUã€MATHã€GaoKaoã€SciQã€SciEvalã€SAT-Math å’Œ AQUA-RAT ä¸Šçš„ 5-shot æ¨ç†æ€§èƒ½ï¼ŒMBPP ä¸Šçš„ 3-shot æ€§èƒ½ã€‚
å¯¹äº HumanEval å’Œ ARCï¼Œæˆ‘ä»¬æŠ¥å‘Šäº† 0-shot æ€§èƒ½ã€‚æœ€ä½³å’Œæ¬¡ä½³ç»“æœåˆ†åˆ«ä»¥ **ç²—ä½“** å’Œ _æ–œä½“_ æ ‡å‡ºã€‚

### ä¸»è¦åŸºå‡†

|       **æ¨¡å‹**         | **MMLU**      | **C-Eval** | **CMMLU** | **MATH**      | **GSM8K** | **ASDiv** | **MAWPS** | **SAT-Math** | **HumanEval** | **MBPP** |
|---------------------------|---------------|----------|---------|---------------|---------|---------|---------|-----------|----------------|--------|
| Llama-3-8B            | **66.60**     | 49.43    | 51.03   | 16.20         | 54.40   | 72.10   | 89.30   | 38.64     | _36.59_        | **47.00** |
| DCLM-7B               | 64.01         | 41.24    | 40.89   | 14.10         | 39.20   | 67.10   | 83.40   | _41.36_   | 21.95          | 32.60  |
| Mistral-7B-v0.3       | 63.54         | 42.74    | 43.72   | 12.30         | 40.50   | 67.50   | 87.50   | 40.45     | 25.61          | 36.00  |
| Llama-3-Chinese-8B    | 64.10         | _50.14_  | _51.20_ | 3.60          | 0.80    | 1.90    | 0.60    | 36.82     | 9.76           | 14.80  |
| MAmmoTH2-8B           | 64.89         | 46.56    | 45.90   | **34.10**     | **61.70**| **82.80**| _91.50_ | _41.36_   | 17.68          | 38.80  |
| Galactica-6.7B        | 37.13         | 26.72    | 25.53   | 5.30          | 9.60    | 40.90   | 51.70   | 23.18     | 7.31           | 2.00   |
| **Llama-3-SynE (ours)**   | _65.19_       | **58.24**| **57.34**| _28.20_      | _60.80_ | _81.00_ | **94.10**| **43.64**| **42.07**      | _45.60_|

> åœ¨ **ä¸­æ–‡è¯„ä¼°åŸºå‡†**ï¼ˆå¦‚ C-Eval å’Œ CMMLUï¼‰ä¸Šï¼ŒLlama-3-SynE æ˜¾è‘—ä¼˜äºåŸºç¡€æ¨¡å‹ Llama-3ï¼ˆ8Bï¼‰ï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨æå‡ä¸­æ–‡è¯­è¨€èƒ½åŠ›æ–¹é¢éå¸¸æœ‰æ•ˆã€‚

> åœ¨ **è‹±æ–‡è¯„ä¼°åŸºå‡†**ï¼ˆå¦‚ MMLUã€MATH å’Œä»£ç è¯„ä¼°åŸºå‡†ï¼‰ä¸Šï¼ŒLlama-3-SynE å±•ç°å‡ºä¸åŸºç¡€æ¨¡å‹ç›¸å½“æˆ–æ›´å¥½çš„æ€§èƒ½ï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç»§ç»­é¢„è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚

### ç§‘å­¦åŸºå‡†

â€œPHYâ€ã€â€œCHEâ€ å’Œ â€œBIOâ€ åˆ†åˆ«è¡¨ç¤ºå¯¹åº”åŸºå‡†çš„ç‰©ç†ã€åŒ–å­¦å’Œç”Ÿç‰©å­ä»»åŠ¡ã€‚

| **æ¨¡å‹**         | **SciEval PHY** | **SciEval CHE** | **SciEval BIO** | **SciEval Avg.** | **SciQ** | **GaoKao MathQA** | **GaoKao CHE** | **GaoKao BIO** | **ARC Easy** | **ARC Challenge** | **ARC Avg.** | **AQUA-RAT** |
|--------------------|-----------------|-----------------|-----------------|------------------|---------------|-------------------|----------------|----------------|---------------|-------------------|--------------|-------------------|
| Llama-3-8B         | 46.95           | 63.45           | 74.53           | 65.47            | 90.90         | 27.92             | 32.85          | 43.81          | 91.37         | 77.73             | 84.51        | _27.95_           |
| DCLM-7B            | **56.71**       | 64.39           | 72.03           | 66.25            | **92.50**     | 29.06             | 31.40          | 37.14          | 89.52         | 76.37             | 82.94        | 20.08             |
| Mistral-7B-v0.3    | 48.17           | 59.41           | 68.89           | 61.51            | 89.40         | 30.48             | 30.92          | 41.43          | 87.33         | 74.74             | 81.04        | 23.23             |
| Llama-3-Chinese-8B | 48.17           | 67.34           | 73.90           | _67.34_          | 89.20         | 27.64             | 30.43          | 38.57          | 88.22         | 70.48             | 79.35        | 27.56             |
| MAmmoTH2-8B        | 49.39           | **69.36**       | _76.83_         | **69.60**        | 90.20         | **32.19**         | _36.23_        | _49.05_        | **92.85**     | **84.30**         | **88.57**    | 27.17             |
| Galactica-6.7B     | 34.76           | 43.39           | 54.07           | 46.27            | 71.50         | 23.65             | 27.05          | 24.76          | 65.91         | 46.76             | 56.33        | 20.87             |
| **Llama-3-SynE (ours)** | _53.66_   | _67.81_         | **77.45**       | **69.60**        | _91.20_       | _31.05_           | **51.21**      | **69.52**      | _91.58_       | _80.97_           | _86.28_      | **28.74**         |

> åœ¨ **ç§‘å­¦è¯„ä¼°åŸºå‡†**ï¼ˆå¦‚ SciEvalã€GaoKao å’Œ ARCï¼‰ä¸Šï¼ŒLlama-3-SynE æ˜¾è‘—ä¼˜äºåŸºç¡€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸­æ–‡ç§‘å­¦åŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼ˆä¾‹å¦‚ï¼Œé«˜è€ƒç”Ÿç‰©å­æµ‹è¯•ä¸­æå‡äº† 25.71%ï¼‰ã€‚

## å¿«é€Ÿå¼€å§‹

åŸºäº transformers è¿›è¡Œæ¨ç†ï¼š

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

model_path = "survivi/Llama-3-SynE"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    model_path, torch_dtype=torch.bfloat16, trust_remote_code=True
)
model.to("cuda:0")
model.eval()
prompt = "Hello world!"
inputs = tokenizer(prompt, return_tensors="pt")
inputs = inputs.to("cuda")
pred = model.generate(
    **inputs,
    max_new_tokens=2048,
    repetition_penalty=1.05,
    temperature=0.5,
    top_k=5,
    top_p=0.85,
    do_sample=True
)
pred = pred[0][len(inputs.input_ids[0]) :]
output = tokenizer.decode(pred, skip_special_tokens=True)
print(output)
```

åŸºäº vLLM è¿›è¡Œæ¨ç†ï¼š

```python
from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

model_path = "survivi/Llama-3-SynE"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
sampling_params = SamplingParams(
    max_tokens=2048,
    repetition_penalty=1.05,
    temperature=0.5,
    top_k=5,
    top_p=0.85,
)
llm = LLM(
    model=model_path,
    tensor_parallel_size=1,
    trust_remote_code=True,
)
prompt = "Hello world!"
output = llm.generate(prompt, sampling_params)
output = output[0].outputs[0].text
print(output)
```

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº Meta çš„ Llama-3 æ¨¡å‹å¼€å‘ï¼ŒLlama-3-SynE æ¨¡å‹æƒé‡çš„ä½¿ç”¨å¿…é¡»éµå¾ª Llama-3 [è®¸å¯åè®®](https://github.com/meta-llama/llama3/blob/main/LICENSE)ã€‚æ­¤å¼€æºä»£ç åº“ä¸­çš„ä»£ç éµå¾ª [Apache 2.0](LICENSE) è®¸å¯è¯ã€‚

## å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```
@article{jie2024llama3syne,
  title={Towards Effective and Efficient Continual Pre-training of Large Language Models},
  author={Chen, Jie and Chen, Zhipeng and Wang, Jiapeng and Zhou, Kun and Zhu, Yutao and Jiang, Jinhao and Min, Yingqian and Zhao, Wayne Xin and Dou, Zhicheng and Mao, Jiaxin and others},
  journal={arXiv preprint arXiv:2407.18743},
  year={2024}
}
```
